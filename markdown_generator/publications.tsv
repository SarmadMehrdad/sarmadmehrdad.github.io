pub_date	title	venue	excerpt	citation	url_slug	paper_url	slides_url
2025-09-30	Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning	arXiv	Quick informal explanation: We used MO-IRL on human subject data for reaching tasks initiated from various postures to see how the assumed cost features would factor into a humans motion for reaching. Basically, what is a human trying to optimize. Another important avenue we pursued was to use multiple weight sections throughout the course of human generated trajectories instead of constant weights (as in MPC for example).	"Mehrdad, Sarmad, Maxime Sabbah, Vincent Bonnet, and Ludovic Righetti. ""Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning."" arXiv preprint arXiv:2510.00329 (2025)."	Mo-irl-human-pred		
2025	Minimal Observations Inverse Reinforcement Learning for Predicting Human Box-Lifting Motions	IEEE - International Conference on Humanoid Robots		"Sabbah, Maxime, Filip Bečanović, Sarmad Mehrdad, Ludovic Righetti, Bruno Watier, and Vincent Bonnet. ""Minimal Observations Inverse Reinforcement Learning for Predicting Human Box-Lifting Motions."" In <i>International Conference on Humanoid Robots 2025</i>. 2025."	Mo-irl-box-lift		
